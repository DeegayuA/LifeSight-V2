(()=>{var m={};m.id=466,m.ids=[466],m.modules={846:m=>{"use strict";m.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},9121:m=>{"use strict";m.exports=require("next/dist/server/app-render/action-async-storage.external.js")},3295:m=>{"use strict";m.exports=require("next/dist/server/app-render/after-task-async-storage.external.js")},9294:m=>{"use strict";m.exports=require("next/dist/server/app-render/work-async-storage.external.js")},3033:m=>{"use strict";m.exports=require("next/dist/server/app-render/work-unit-async-storage.external.js")},3873:m=>{"use strict";m.exports=require("path")},2309:(m,e,x)=>{"use strict";x.r(e),x.d(e,{GlobalError:()=>r.a,__next_app__:()=>c,pages:()=>o,routeModule:()=>d,tree:()=>i});var b=x(260),n=x(8203),t=x(5155),r=x.n(t),s=x(7292),a={};for(let m in s)0>["default","tree","pages","GlobalError","__next_app__","routeModule"].indexOf(m)&&(a[m]=()=>s[m]);x.d(e,a);let i=["",{children:["app",{children:["__PAGE__",{},{page:[()=>Promise.resolve().then(x.bind(x,1064)),"/Users/deeghayuadhikari/Documents/LifeSight/app/app/page.tsx"]}]},{}]},{layout:[()=>Promise.resolve().then(x.bind(x,2530)),"/Users/deeghayuadhikari/Documents/LifeSight/app/layout.tsx"],"not-found":[()=>Promise.resolve().then(x.bind(x,1129)),"/Users/deeghayuadhikari/Documents/LifeSight/app/not-found.tsx"],forbidden:[()=>Promise.resolve().then(x.t.bind(x,9116,23)),"next/dist/client/components/forbidden-error"],unauthorized:[()=>Promise.resolve().then(x.t.bind(x,1485,23)),"next/dist/client/components/unauthorized-error"]}],o=["/Users/deeghayuadhikari/Documents/LifeSight/app/app/page.tsx"],c={require:x,loadChunk:()=>Promise.resolve()},d=new b.AppPageRouteModule({definition:{kind:n.RouteKind.APP_PAGE,page:"/app/page",pathname:"/app",bundlePath:"",filename:"",appPaths:[]},userland:{loaderTree:i}})},2697:(m,e,x)=>{Promise.resolve().then(x.bind(x,1064))},7849:(m,e,x)=>{Promise.resolve().then(x.bind(x,7218))},7218:(m,e,x)=>{"use strict";x.r(e),x.d(e,{default:()=>h});var b=x(5512),n=x(8009),t=x(3747),r=x(7021),s=x(1965),a=x(1680);let i=(0,a.A)("Camera",[["path",{d:"M14.5 4h-5L7 7H4a2 2 0 0 0-2 2v9a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2h-3l-2.5-3z",key:"1tc9qg"}],["circle",{cx:"12",cy:"13",r:"3",key:"1vg3eu"}]]),o=(0,a.A)("Mic",[["path",{d:"M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z",key:"131961"}],["path",{d:"M19 10v2a7 7 0 0 1-14 0v-2",key:"1vc78b"}],["line",{x1:"12",x2:"12",y1:"19",y2:"22",key:"x3vr5v"}]]),c=(0,a.A)("MessageSquare",[["path",{d:"M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z",key:"1lielz"}]]),d=(0,a.A)("Check",[["path",{d:"M20 6 9 17l-5-5",key:"1gmf2c"}]]);var l=x(691);function u({onComplete:m}){let{fontSize:e,accentColor:x}=(0,l.t)();return(0,b.jsx)(s.lG,{open:!0,onOpenChange:m,children:(0,b.jsxs)(s.Cf,{className:"sm:max-w-[425px]",style:{fontSize:`${e/16}rem`},children:[(0,b.jsxs)(s.c7,{children:[(0,b.jsx)(s.L3,{children:"Welcome to Lifesight"}),(0,b.jsx)(s.rr,{children:"Let's get you started with using our AI-powered assistant."})]}),(0,b.jsxs)("div",{className:"py-4 space-y-4",children:[(0,b.jsxs)("div",{className:"flex items-start space-x-3",children:[(0,b.jsx)(i,{className:"w-5 h-5 mt-0.5",style:{color:x}}),(0,b.jsxs)("div",{children:[(0,b.jsx)("h3",{className:"font-medium",children:"Camera Access"}),(0,b.jsx)("p",{className:"text-sm text-muted-foreground",children:"We'll use your camera to help understand your surroundings"})]})]}),(0,b.jsxs)("div",{className:"flex items-start space-x-3",children:[(0,b.jsx)(o,{className:"w-5 h-5 mt-0.5",style:{color:x}}),(0,b.jsxs)("div",{children:[(0,b.jsx)("h3",{className:"font-medium",children:"Voice Commands"}),(0,b.jsx)("p",{className:"text-sm text-muted-foreground",children:"Speak naturally to interact with the assistant"})]})]}),(0,b.jsxs)("div",{className:"flex items-start space-x-3",children:[(0,b.jsx)(c,{className:"w-5 h-5 mt-0.5",style:{color:x}}),(0,b.jsxs)("div",{children:[(0,b.jsx)("h3",{className:"font-medium",children:"Text Input"}),(0,b.jsx)("p",{className:"text-sm text-muted-foreground",children:"Type your questions if you prefer text communication"})]})]})]}),(0,b.jsx)(s.Es,{children:(0,b.jsxs)(r.$,{onClick:m,className:"w-full",style:{backgroundColor:x},children:[(0,b.jsx)(d,{className:"w-4 h-4 mr-2"}),"Get Started"]})})]})})}var p=x(3197),f=x(9462),g=x(1844);function h(){let[m,e]=(0,p.M)("hasSeenOnboarding",!1),[x,r]=(0,n.useState)(!1);return x?(0,b.jsx)(b.Fragment,{children:(0,b.jsx)("main",{className:(0,f.cn)("bg-background overflow-hidden"),children:(0,b.jsxs)(g.Bc,{children:[(0,b.jsx)(t.J,{}),!m&&(0,b.jsx)(u,{onComplete:()=>e(!0)})]})})}):null}},3747:()=>{throw Error("Module build failed (from ./node_modules/next/dist/build/webpack/loaders/next-swc-loader.js):\nError:   \x1b[31mx\x1b[0m Expected ';', '}' or <eof>\n     ,-[\x1b[36;1;4m/Users/deeghayuadhikari/Documents/LifeSight/components/main-interface.tsx\x1b[0m:1:1]\n \x1b[2m  1\x1b[0m | \x1b[35;1m,\x1b[0m\x1b[35;1m-\x1b[0m\x1b[35;1m>\x1b[0m {`\"use client\";\n \x1b[2m  2\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m  3\x1b[0m | \x1b[35;1m|\x1b[0m       import { useState, useRef, useEffect, useCallback } from 'react';\n \x1b[2m  4\x1b[0m | \x1b[35;1m|\x1b[0m       import { Button } from '@/components/ui/button';\n \x1b[2m  5\x1b[0m | \x1b[35;1m|\x1b[0m       import { Card } from '@/components/ui/card';\n \x1b[2m  6\x1b[0m | \x1b[35;1m|\x1b[0m       import { Input } from '@/components/ui/input';\n \x1b[2m  7\x1b[0m | \x1b[35;1m|\x1b[0m       import { Camera, Mic, MicOff, CameraOff, Send, Volume2, VolumeX, Phone } from 'lucide-react';\n \x1b[2m  8\x1b[0m | \x1b[35;1m|\x1b[0m       import { useAIResponse } from '@/hooks/use-ai-response';\n \x1b[2m  9\x1b[0m | \x1b[35;1m|\x1b[0m       import { AIResponseDisplay } from '@/components/ai-response-display';\n \x1b[2m 10\x1b[0m | \x1b[35;1m|\x1b[0m       import { useLanguage } from '@/components/language-provider';\n \x1b[2m 11\x1b[0m | \x1b[35;1m|\x1b[0m       import { cn } from '@/lib/utils';\n \x1b[2m 12\x1b[0m | \x1b[35;1m|\x1b[0m       import {\n \x1b[2m 13\x1b[0m | \x1b[35;1m|\x1b[0m         Tooltip,\n \x1b[2m 14\x1b[0m | \x1b[35;1m|\x1b[0m         TooltipContent,\n \x1b[2m 15\x1b[0m | \x1b[35;1m|\x1b[0m         TooltipTrigger,\n \x1b[2m 16\x1b[0m | \x1b[35;1m|\x1b[0m       } from '@/components/ui/tooltip';\n \x1b[2m 17\x1b[0m | \x1b[35;1m|\x1b[0m       import { useSettings } from '@/components/settings-provider';\n \x1b[2m 18\x1b[0m | \x1b[35;1m|\x1b[0m       import { SettingsPanel } from '@/components/settings-panel';\n \x1b[2m 19\x1b[0m | \x1b[35;1m|\x1b[0m       import Link from 'next/link';\n \x1b[2m 20\x1b[0m | \x1b[35;1m|\x1b[0m       import { useSpeech } from '@/hooks/use-speech';\n \x1b[2m 21\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 22\x1b[0m | \x1b[35;1m|\x1b[0m       export function MainInterface() {\n \x1b[2m 23\x1b[0m | \x1b[35;1m|\x1b[0m         const [isCameraOn, setIsCameraOn] = useState(false);\n \x1b[2m 24\x1b[0m | \x1b[35;1m|\x1b[0m         const [isMicOn, setIsMicOn] = useState(false);\n \x1b[2m 25\x1b[0m | \x1b[35;1m|\x1b[0m         const [textInput, setTextInput] = useState('');\n \x1b[2m 26\x1b[0m | \x1b[35;1m|\x1b[0m         const [selectedCamera, setSelectedCamera] = useState<string>('');\n \x1b[2m 27\x1b[0m | \x1b[35;1m|\x1b[0m         const [selectedMic, setSelectedMic] = useState<string>('');\n \x1b[2m 28\x1b[0m | \x1b[35;1m|\x1b[0m         const [devices, setDevices] = useState<{ cameras: MediaDeviceInfo[], mics: MediaDeviceInfo[] }>({\n \x1b[2m 29\x1b[0m | \x1b[35;1m|\x1b[0m           cameras: [],\n \x1b[2m 30\x1b[0m | \x1b[35;1m|\x1b[0m           mics: []\n \x1b[2m 31\x1b[0m | \x1b[35;1m|\x1b[0m         });\n \x1b[2m 32\x1b[0m | \x1b[35;1m|\x1b[0m         const [micPausedForPlayback, setMicPausedForPlayback] = useState(false);\n \x1b[2m 33\x1b[0m | \x1b[35;1m|\x1b[0m         const [settingsOpen, setSettingsOpen] = useState(false);\n \x1b[2m 34\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 35\x1b[0m | \x1b[35;1m|\x1b[0m         const videoRef = useRef<HTMLVideoElement>(null);\n \x1b[2m 36\x1b[0m | \x1b[35;1m|\x1b[0m         const mediaStreamRef = useRef<MediaStream | null>(null);\n \x1b[2m 37\x1b[0m | \x1b[35;1m|\x1b[0m         const { isLoading, response, getResponse } = useAIResponse();\n \x1b[2m 38\x1b[0m | \x1b[35;1m|\x1b[0m         const { language } = useLanguage();\n \x1b[2m 39\x1b[0m | \x1b[35;1m|\x1b[0m         const recognitionRef = useRef<any | null>(null);\n \x1b[2m 40\x1b[0m | \x1b[35;1m|\x1b[0m         const synthRef = useRef<SpeechSynthesisUtterance | null>(null);\n \x1b[2m 41\x1b[0m | \x1b[35;1m|\x1b[0m         const { fontSize, lineHeight, letterSpacing, accentColor } = useSettings();\n \x1b[2m 42\x1b[0m | \x1b[35;1m|\x1b[0m         const { speak, stop: stopSpeaking, isPlaying: isSpeechPlaying } = useSpeech({\n \x1b[2m 43\x1b[0m | \x1b[35;1m|\x1b[0m           onStart: () => {\n \x1b[2m 44\x1b[0m | \x1b[35;1m|\x1b[0m             if (isMicOn) {\n \x1b[2m 45\x1b[0m | \x1b[35;1m|\x1b[0m               toggleMic(false);\n \x1b[2m 46\x1b[0m | \x1b[35;1m|\x1b[0m               setMicPausedForPlayback(true);\n \x1b[2m 47\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m 48\x1b[0m | \x1b[35;1m|\x1b[0m           },\n \x1b[2m 49\x1b[0m | \x1b[35;1m|\x1b[0m           onEnd: () => {\n \x1b[2m 50\x1b[0m | \x1b[35;1m|\x1b[0m             if (micPausedForPlayback) {\n \x1b[2m 51\x1b[0m | \x1b[35;1m|\x1b[0m               toggleMic(true);\n \x1b[2m 52\x1b[0m | \x1b[35;1m|\x1b[0m               setMicPausedForPlayback(false);\n \x1b[2m 53\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m 54\x1b[0m | \x1b[35;1m|\x1b[0m           },\n \x1b[2m 55\x1b[0m | \x1b[35;1m|\x1b[0m           onError: (error) => {\n \x1b[2m 56\x1b[0m | \x1b[35;1m|\x1b[0m             console.error('Speech synthesis error:', error);\n \x1b[2m 57\x1b[0m | \x1b[35;1m|\x1b[0m             if (micPausedForPlayback) {\n \x1b[2m 58\x1b[0m | \x1b[35;1m|\x1b[0m               toggleMic(true);\n \x1b[2m 59\x1b[0m | \x1b[35;1m|\x1b[0m               setMicPausedForPlayback(false);\n \x1b[2m 60\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m 61\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m 62\x1b[0m | \x1b[35;1m|\x1b[0m         });\n \x1b[2m 63\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 64\x1b[0m | \x1b[35;1m|\x1b[0m         useEffect(() => {\n \x1b[2m 65\x1b[0m | \x1b[35;1m|\x1b[0m           async function getDevices() {\n \x1b[2m 66\x1b[0m | \x1b[35;1m|\x1b[0m             try {\n \x1b[2m 67\x1b[0m | \x1b[35;1m|\x1b[0m               const devices = await navigator.mediaDevices.enumerateDevices();\n \x1b[2m 68\x1b[0m | \x1b[35;1m|\x1b[0m               const cameras = devices.filter(device => device.kind === 'videoinput');\n \x1b[2m 69\x1b[0m | \x1b[35;1m|\x1b[0m               const mics = devices.filter(device => device.kind === 'audioinput');\n \x1b[2m 70\x1b[0m | \x1b[35;1m|\x1b[0m               setDevices({ cameras, mics });\n \x1b[2m 71\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 72\x1b[0m | \x1b[35;1m|\x1b[0m               // Attempt to select back camera first\n \x1b[2m 73\x1b[0m | \x1b[35;1m|\x1b[0m               let backCamera = cameras.find(camera => camera.label.toLowerCase().includes('back'));\n \x1b[2m 74\x1b[0m | \x1b[35;1m|\x1b[0m               if (!backCamera && cameras.length > 0) {\n \x1b[2m 75\x1b[0m | \x1b[35;1m|\x1b[0m                 backCamera = cameras.find(camera => camera.facingMode === 'environment') || cameras[0];\n \x1b[2m 76\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m 77\x1b[0m | \x1b[35;1m|\x1b[0m               if (backCamera) setSelectedCamera(backCamera.deviceId);\n \x1b[2m 78\x1b[0m | \x1b[35;1m|\x1b[0m               if (mics.length) setSelectedMic(mics[0].deviceId);\n \x1b[2m 79\x1b[0m | \x1b[35;1m|\x1b[0m             } catch (error) {\n \x1b[2m 80\x1b[0m | \x1b[35;1m|\x1b[0m               console.error('Error getting devices:', error);\n \x1b[2m 81\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m 82\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m 83\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 84\x1b[0m | \x1b[35;1m|\x1b[0m           getDevices();\n \x1b[2m 85\x1b[0m | \x1b[35;1m|\x1b[0m         }, []);\n \x1b[2m 86\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 87\x1b[0m | \x1b[35;1m|\x1b[0m         useEffect(() => {\n \x1b[2m 88\x1b[0m | \x1b[35;1m|\x1b[0m           const startMedia = async () => {\n \x1b[2m 89\x1b[0m | \x1b[35;1m|\x1b[0m             await toggleCamera(true);\n \x1b[2m 90\x1b[0m | \x1b[35;1m|\x1b[0m             await toggleMic(true);\n \x1b[2m 91\x1b[0m | \x1b[35;1m|\x1b[0m           };\n \x1b[2m 92\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 93\x1b[0m | \x1b[35;1m|\x1b[0m           startMedia();\n \x1b[2m 94\x1b[0m | \x1b[35;1m|\x1b[0m         }, []);\n \x1b[2m 95\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m 96\x1b[0m | \x1b[35;1m|\x1b[0m         const toggleCamera = async (forceOn: boolean = false) => {\n \x1b[2m 97\x1b[0m | \x1b[35;1m|\x1b[0m           try {\n \x1b[2m 98\x1b[0m | \x1b[35;1m|\x1b[0m             if (isCameraOn || forceOn) {\n \x1b[2m 99\x1b[0m | \x1b[35;1m|\x1b[0m               if (mediaStreamRef.current) {\n \x1b[2m100\x1b[0m | \x1b[35;1m|\x1b[0m                 mediaStreamRef.current.getTracks().forEach(track => track.stop());\n \x1b[2m101\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m102\x1b[0m | \x1b[35;1m|\x1b[0m               if (videoRef.current) {\n \x1b[2m103\x1b[0m | \x1b[35;1m|\x1b[0m                 videoRef.current.srcObject = null;\n \x1b[2m104\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m105\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m106\x1b[0m | \x1b[35;1m|\x1b[0m             if (!isCameraOn || forceOn) {\n \x1b[2m107\x1b[0m | \x1b[35;1m|\x1b[0m               const stream = await navigator.mediaDevices.getUserMedia({\n \x1b[2m108\x1b[0m | \x1b[35;1m|\x1b[0m                 video: { deviceId: selectedCamera }\n \x1b[2m109\x1b[0m | \x1b[35;1m|\x1b[0m               });\n \x1b[2m110\x1b[0m | \x1b[35;1m|\x1b[0m               if (videoRef.current) {\n \x1b[2m111\x1b[0m | \x1b[35;1m|\x1b[0m                 videoRef.current.srcObject = stream;\n \x1b[2m112\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m113\x1b[0m | \x1b[35;1m|\x1b[0m               mediaStreamRef.current = stream;\n \x1b[2m114\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m115\x1b[0m | \x1b[35;1m|\x1b[0m             setIsCameraOn(!isCameraOn || forceOn);\n \x1b[2m116\x1b[0m | \x1b[35;1m|\x1b[0m           } catch (error) {\n \x1b[2m117\x1b[0m | \x1b[35;1m|\x1b[0m             console.error('Error toggling camera:', error);\n \x1b[2m118\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m119\x1b[0m | \x1b[35;1m|\x1b[0m         };\n \x1b[2m120\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m121\x1b[0m | \x1b[35;1m|\x1b[0m         const toggleMic = async (forceOn: boolean = false) => {\n \x1b[2m122\x1b[0m | \x1b[35;1m|\x1b[0m           try {\n \x1b[2m123\x1b[0m | \x1b[35;1m|\x1b[0m             if (isMicOn && !forceOn) {\n \x1b[2m124\x1b[0m | \x1b[35;1m|\x1b[0m               if (mediaStreamRef.current) {\n \x1b[2m125\x1b[0m | \x1b[35;1m|\x1b[0m                 mediaStreamRef.current.getTracks().forEach(track => {\n \x1b[2m126\x1b[0m | \x1b[35;1m|\x1b[0m                   if (track.kind === 'audio') track.stop();\n \x1b[2m127\x1b[0m | \x1b[35;1m|\x1b[0m                 });\n \x1b[2m128\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m129\x1b[0m | \x1b[35;1m|\x1b[0m               if (recognitionRef.current) {\n \x1b[2m130\x1b[0m | \x1b[35;1m|\x1b[0m                 recognitionRef.current.stop();\n \x1b[2m131\x1b[0m | \x1b[35;1m|\x1b[0m               }\n \x1b[2m132\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m133\x1b[0m | \x1b[35;1m|\x1b[0m             if (!isMicOn || forceOn) {\n \x1b[2m134\x1b[0m | \x1b[35;1m|\x1b[0m               const stream = await navigator.mediaDevices.getUserMedia({\n \x1b[2m135\x1b[0m | \x1b[35;1m|\x1b[0m                 audio: { deviceId: selectedMic }\n \x1b[2m136\x1b[0m | \x1b[35;1m|\x1b[0m               });\n \x1b[2m137\x1b[0m | \x1b[35;1m|\x1b[0m               mediaStreamRef.current = stream;\n \x1b[2m138\x1b[0m | \x1b[35;1m|\x1b[0m               startSpeechRecognition();\n \x1b[2m139\x1b[0m | \x1b[35;1m|\x1b[0m             }\n \x1b[2m140\x1b[0m | \x1b[35;1m|\x1b[0m             setIsMicOn(!isMicOn || forceOn);\n \x1b[2m141\x1b[0m | \x1b[35;1m|\x1b[0m           } catch (error) {\n \x1b[2m142\x1b[0m | \x1b[35;1m|\x1b[0m             console.error('Error toggling microphone:', error);\n \x1b[2m143\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m144\x1b[0m | \x1b[35;1m|\x1b[0m         };\n \x1b[2m145\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m146\x1b[0m | \x1b[35;1m|\x1b[0m         const captureImage = async (): Promise<string | null> => {\n \x1b[2m147\x1b[0m | \x1b[35;1m|\x1b[0m           if (!videoRef.current) return null;\n \x1b[2m148\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m149\x1b[0m | \x1b[35;1m|\x1b[0m           const canvas = document.createElement('canvas');\n \x1b[2m150\x1b[0m | \x1b[35;1m|\x1b[0m           canvas.width = videoRef.current.videoWidth;\n \x1b[2m151\x1b[0m | \x1b[35;1m|\x1b[0m           canvas.height = videoRef.current.videoHeight;\n \x1b[2m152\x1b[0m | \x1b[35;1m|\x1b[0m           const ctx = canvas.getContext('2d');\n \x1b[2m153\x1b[0m | \x1b[35;1m|\x1b[0m           if (!ctx) return null;\n \x1b[2m154\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m155\x1b[0m | \x1b[35;1m|\x1b[0m           ctx.drawImage(videoRef.current, 0, 0);\n \x1b[2m156\x1b[0m | \x1b[35;1m|\x1b[0m           return canvas.toDataURL('image/jpeg').split(',')[1];\n \x1b[2m157\x1b[0m | \x1b[35;1m|\x1b[0m         };\n \x1b[2m158\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m159\x1b[0m | \x1b[35;1m|\x1b[0m         const handleSubmit = async () => {\n \x1b[2m160\x1b[0m | \x1b[35;1m|\x1b[0m           if (!textInput.trim()) return;\n \x1b[2m161\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m162\x1b[0m | \x1b[35;1m|\x1b[0m           const imageBase64 = isCameraOn ? await captureImage() : undefined;\n \x1b[2m163\x1b[0m | \x1b[35;1m|\x1b[0m           await getResponse(textInput, typeof imageBase64 === 'string' ? imageBase64 : undefined);\n \x1b[2m164\x1b[0m | \x1b[35;1m|\x1b[0m           setTextInput('');\n \x1b[2m165\x1b[0m | \x1b[35;1m|\x1b[0m         };\n \x1b[2m166\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m167\x1b[0m | \x1b[35;1m|\x1b[0m         const handleResponseEnd = () => {\n \x1b[2m168\x1b[0m | \x1b[35;1m|\x1b[0m           if (isMicOn) {\n \x1b[2m169\x1b[0m | \x1b[35;1m|\x1b[0m             toggleMic();\n \x1b[2m170\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m171\x1b[0m | \x1b[35;1m|\x1b[0m         };\n \x1b[2m172\x1b[0m | \x1b[35;1m|\x1b[0m   \n \x1b[2m173\x1b[0m | \x1b[35;1m|\x1b[0m         const startSpeechRecognition = () => {\n \x1b[2m174\x1b[0m | \x1b[35;1m|\x1b[0m           if (typeof window === 'undefined' || !('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {\n \x1b[2m175\x1b[0m | \x1b[35;1m|\x1b[0m             console.error('Speech recognition is not supported in this browser.');\n \x1b[2m176\x1b[0m | \x1b[35;1m|\x1b[0m             return;\n \x1b[2m177\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m178\x1b[0m | \x1b[35;1m|\x1b[0m         \n \x1b[2m179\x1b[0m | \x1b[35;1m|\x1b[0m           const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;\n \x1b[2m180\x1b[0m | \x1b[35;1m|\x1b[0m           if (!SpeechRecognition) {\n \x1b[2m181\x1b[0m | \x1b[35;1m|\x1b[0m             console.error('Speech recognition is not supported in this browser.');\n \x1b[2m182\x1b[0m | \x1b[35;1m|\x1b[0m             return;\n \x1b[2m183\x1b[0m | \x1b[35;1m|\x1b[0m           }\n \x1b[2m184\x1b[0m | \x1b[35;1m|\x1b[0m         \n \x1b[2m185\x1b[0m | \x1b[35;1m|\x1b[0m           recognitionRef.current = new SpeechRecognition();\n \x1b[2m186\x1b[0m | \x1b[35;1m|\x1b[0m           recognitionRef.current.lang = language;\n \x1b[2m187\x1b[0m | \x1b[35;1m|\x1b[0m           recognitionRef.current.interimResults = false;\n \x1b[2m188\x1b[0m | \x1b[35;1m|\x1b[0m           recognitionRef.current.maxAlternatives = 1;\n \x1b[2m189\x1b[0m | \x1b[35;1m|\x1b[0m         \n \x1b[2m190\x1b[0m | \x1b[35;1m|\x1b[0m           recognitionRef.current.onresult = async (event: any) => {\n \x1b[2m191\x1b[0m | \x1b[35;1m|\x1b[0m             const transcript = event.results[0][0].transcript.trim().toLowerCase();\n \x1b[2m192\x1b[0m | \x1b[35;1m|\x1b[0m\x1b[35;1m-\x1b[0m\x1b[35;1m>\x1b[0m           console.log(`Voice command detected: \"${transcript}\"`);\n     : \x1b[35;1m`\x1b[0m\x1b[35;1m---\x1b[0m\x1b[33;1m                       ^^^^^\x1b[0m\n     : \x1b[35;1m`\x1b[0m\x1b[35;1m---\x1b[0m\x1b[35;1m-\x1b[0m \x1b[35;1mThis is the expression part of an expression statement\x1b[0m\n \x1b[2m193\x1b[0m |           \n \x1b[2m194\x1b[0m |               // Pause mic for processing commands\n \x1b[2m195\x1b[0m |               await toggleMic(false);\n     `----\n\n\nCaused by:\n    Syntax Error")},1064:(m,e,x)=>{"use strict";x.r(e),x.d(e,{default:()=>b});let b=(0,x(6760).registerClientReference)(function(){throw Error("Attempted to call the default export of \"/Users/deeghayuadhikari/Documents/LifeSight/app/app/page.tsx\" from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.")},"/Users/deeghayuadhikari/Documents/LifeSight/app/app/page.tsx","default")}};var e=require("../../webpack-runtime.js");e.C(m);var x=m=>e(e.s=m),b=e.X(0,[276,14],()=>x(2309));module.exports=b})();